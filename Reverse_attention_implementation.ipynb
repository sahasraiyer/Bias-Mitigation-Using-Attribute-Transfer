{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reverse_attention_implementation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg6zAgbdMaDE"
      },
      "source": [
        "!pip install bertviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LRMAUN9MLrl"
      },
      "source": [
        "from bertviz import head_view\n",
        "from transformers import XLNetTokenizer, XLNetModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XL-NET classifier**"
      ],
      "metadata": {
        "id": "S_sUld4Zeb2d"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x35lrXiDMNXO"
      },
      "source": [
        "from transformers import XLNetTokenizer, XLNetModel\n",
        "model_version = 'xlnet-base-cased'\n",
        "model = XLNetModel.from_pretrained(model_version, output_attentions=True)\n",
        "tokenizer = XLNetTokenizer.from_pretrained(model_version)\n",
        "\n",
        "text = \"The quick brown fox jumps over the lazy dogs.\"\n",
        "inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=True)\n",
        "input_ids = inputs['input_ids']\n",
        "attention = model(input_ids)[-1]\n",
        "input_id_list = input_ids[0].tolist() # Batch index 0\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
        "print(attention)\n",
        "head_view(attention, tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDd2J7JTVPec",
        "outputId": "79d63ac3-b82b-4c9e-890e-f3b1d4c89d1b"
      },
      "source": [
        "#CLS token representation for last layer for head 0\n",
        "import torch\n",
        "print(torch.sum(attention[0][0][-1][-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0000, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating attention for the sentence**"
      ],
      "metadata": {
        "id": "LODn5gc4epGC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj3cPVTRZlz_",
        "outputId": "46ef9182-ee59-4d5f-a9a2-ee9745377980"
      },
      "source": [
        "#finding the max attention for the CLS token for last layer\n",
        "attention_max = attention[0][0][-1][-1]\n",
        "for a in attention:\n",
        "  att = a[0][-1][-1]\n",
        "  print(att)\n",
        "  print(torch.sum(att))\n",
        "  attention_max = torch.max(att,attention_max)\n",
        "print(torch.norm(attention_max))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0738, 0.0747, 0.0648, 0.0884, 0.0515, 0.0537, 0.1108, 0.2174, 0.0812,\n",
            "        0.0711, 0.0300, 0.0304, 0.0279, 0.0243], grad_fn=<SelectBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor([0.0161, 0.0084, 0.0039, 0.0142, 0.0025, 0.0145, 0.0307, 0.0252, 0.0585,\n",
            "        0.0152, 0.0581, 0.2815, 0.3163, 0.1549], grad_fn=<SelectBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor([6.8712e-02, 5.3705e-02, 2.9311e-03, 5.1748e-01, 8.5324e-04, 2.1432e-02,\n",
            "        3.2033e-02, 1.1316e-02, 2.0100e-01, 3.3107e-03, 3.6151e-04, 5.0048e-02,\n",
            "        4.6718e-03, 3.2146e-02], grad_fn=<SelectBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([0.0245, 0.0052, 0.0373, 0.0512, 0.0131, 0.0185, 0.0101, 0.0105, 0.0578,\n",
            "        0.0163, 0.0063, 0.5281, 0.1442, 0.0770], grad_fn=<SelectBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([0.1672, 0.0268, 0.0764, 0.0581, 0.0390, 0.0157, 0.0473, 0.0188, 0.0762,\n",
            "        0.0104, 0.0295, 0.3122, 0.0839, 0.0387], grad_fn=<SelectBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([6.3401e-04, 3.6325e-04, 2.7344e-04, 3.3977e-04, 6.4624e-04, 1.2699e-03,\n",
            "        3.9120e-04, 8.0474e-05, 2.2222e-04, 1.8785e-03, 1.0057e-02, 3.9041e-01,\n",
            "        2.8772e-01, 3.0572e-01], grad_fn=<SelectBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor([0.0377, 0.0571, 0.0249, 0.0109, 0.0040, 0.0059, 0.0050, 0.0532, 0.0031,\n",
            "        0.0093, 0.0196, 0.0348, 0.0818, 0.6526], grad_fn=<SelectBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor([8.1220e-01, 9.8353e-03, 8.8239e-05, 7.6987e-06, 4.4895e-07, 3.4240e-05,\n",
            "        3.6988e-04, 6.6534e-03, 1.7357e-02, 1.2701e-04, 9.6319e-06, 4.6028e-03,\n",
            "        7.0208e-02, 7.8510e-02], grad_fn=<SelectBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([2.8392e-04, 5.7062e-05, 2.5470e-05, 2.8761e-06, 4.9622e-06, 6.4954e-06,\n",
            "        4.4703e-05, 1.1831e-04, 1.8482e-03, 3.5798e-03, 9.9509e-04, 1.6928e-01,\n",
            "        3.0649e-01, 5.1727e-01], grad_fn=<SelectBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor([0.0301, 0.0334, 0.1119, 0.0367, 0.0061, 0.0087, 0.0014, 0.0052, 0.0026,\n",
            "        0.0134, 0.0360, 0.0100, 0.0932, 0.6112], grad_fn=<SelectBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor([0.0089, 0.0711, 0.0272, 0.0273, 0.0091, 0.0335, 0.0063, 0.0107, 0.0622,\n",
            "        0.3898, 0.0238, 0.0610, 0.1115, 0.1576], grad_fn=<SelectBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor([0.0263, 0.0078, 0.0124, 0.0083, 0.0061, 0.0175, 0.0023, 0.0059, 0.0131,\n",
            "        0.0122, 0.0230, 0.0677, 0.2105, 0.5869], grad_fn=<SelectBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor(1.4181, grad_fn=<CopyBackwards>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3ZkNi3NdBCc",
        "outputId": "13b6182a-1537-4b2a-afd1-c869ea3a44e3"
      },
      "source": [
        "normalized_attention_max = torch.nn.functional.softmax(attention_max)\n",
        "print(normalized_attention_max)\n",
        "print(torch.sum(torch.tensor(normalized_attention_max)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1165, 0.0557, 0.0578, 0.0867, 0.0544, 0.0546, 0.0578, 0.0643, 0.0632,\n",
            "        0.0763, 0.0548, 0.0877, 0.0709, 0.0993], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDLVtgRUVyQW",
        "outputId": "08596a4f-5c76-4694-d352-26f1a7db3e2f"
      },
      "source": [
        "len(attention)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating Reverse Attention**"
      ],
      "metadata": {
        "id": "QKCjs2sset6L"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCqk8fJmPTzS",
        "outputId": "38302453-62b3-4c91-8af4-37a2c9ac4258"
      },
      "source": [
        "# -1 gives the reverse - attention of the CLS token\n",
        "import torch\n",
        "reverse_attention =  torch.subtract(torch.tensor(1),torch.tensor(normalized_attention_max))\n",
        "length = normalized_attention_max.shape[0]\n",
        "print(length)\n",
        "#normalizing the reverse attention\n",
        "normalized_reverse_attention = reverse_attention/(length-1)\n",
        "print(torch.sum(normalized_reverse_attention))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "tensor(1.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHLibgHtSCeL"
      },
      "source": [
        "# out = model(**inputs)\n",
        "# print(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0wk5vo9sbEk"
      },
      "source": [
        "## *Getting input embeddings intial*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HirG_nMZqZD0",
        "outputId": "ffa064aa-0fb3-4375-8d32-3c53849d3941"
      },
      "source": [
        "input_embeddings = model.get_input_embeddings()(torch.tensor(inputs['input_ids']))\n",
        "print(\"Initial shape of input embeddings: \", input_embeddings.shape)\n",
        "print(\"Initial shape of normalized_reverse_attention\",normalized_reverse_attention.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial shape of input embeddings:  torch.Size([1, 14, 768])\n",
            "Initial shape of normalized_reverse_attention torch.Size([14])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lhnATusUw6M",
        "outputId": "1489f408-1f0e-4325-e050-7b9ed341058b"
      },
      "source": [
        "input_embeddings = input_embeddings.squeeze(0)\n",
        "normalized_reverse_attention = normalized_reverse_attention.reshape(-1,1)\n",
        "print(\"Initial shape of input embeddings: \", input_embeddings.shape)\n",
        "print(\"Initial shape of normalized_reverse_attention\",normalized_reverse_attention.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial shape of input embeddings:  torch.Size([14, 768])\n",
            "Initial shape of normalized_reverse_attention torch.Size([14, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yRZl9k1kQPt",
        "outputId": "304d5c9d-dc9b-4b46-9b56-15fe21cb1d42"
      },
      "source": [
        "#imposing the reverse attention on the embedding matrix using element-wise multiplication\n",
        "embeddings_updated = torch.mul(normalized_reverse_attention,input_embeddings)\n",
        "print(embeddings_updated)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.2942e-03, -2.2092e-03, -1.9920e-03,  ..., -2.3187e-03,\n",
            "          2.0584e-03, -9.5169e-04],\n",
            "        [ 5.8976e-03, -7.2265e-05, -2.9719e-03,  ...,  1.6594e-03,\n",
            "          4.7470e-03,  4.4126e-03],\n",
            "        [ 1.5321e-03, -1.3371e-04,  5.8807e-03,  ...,  2.0599e-03,\n",
            "          2.6373e-03,  2.1585e-03],\n",
            "        ...,\n",
            "        [-1.6712e-03, -4.2549e-04, -1.1416e-03,  ..., -1.1254e-03,\n",
            "          3.0278e-03, -2.1672e-03],\n",
            "        [ 5.6310e-03, -4.1641e-03, -6.4672e-03,  ...,  3.5257e-03,\n",
            "          4.5281e-03, -3.7160e-03],\n",
            "        [ 1.2563e-03, -1.0350e-04, -1.0353e-02,  ...,  8.0741e-05,\n",
            "         -6.4669e-05,  1.2999e-03]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9az9CiCmaxv",
        "outputId": "a45e07a7-7033-4858-ffd8-76c78337be38"
      },
      "source": [
        "print(embeddings_updated.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([14, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding GRU Layer**"
      ],
      "metadata": {
        "id": "gjJg-DsTfBqv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg2t1tnnwXUw",
        "outputId": "2332a0d8-3c8d-4740-e7d5-502ec8ab5dc1"
      },
      "source": [
        "#applying the GRU layer to the input embeddings\n",
        "with torch.no_grad():\n",
        "  input_gru = embeddings_updated.unsqueeze(0)\n",
        "print(\"input shape: \",input_gru.shape)\n",
        "hidden_gru = torch.rand(size =[2,1,250]) #D=2 for bidirectional\n",
        "print(\"hidden state shape: \",hidden_gru.shape)\n",
        "gru = torch.nn.GRU(input_size=768,hidden_size = 250,num_layers= 1,batch_first = True, bidirectional = True, dropout = 0)\n",
        "gru_output, h_n = gru(input_gru,hidden_gru)\n",
        "print(\"output shape: \", gru_output.shape)\n",
        "print(\"final hidden state shape: \", h_n.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape:  torch.Size([1, 14, 768])\n",
            "hidden state shape:  torch.Size([2, 1, 250])\n",
            "output shape:  torch.Size([1, 14, 500])\n",
            "final hidden state shape:  torch.Size([2, 1, 250])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzN_tXWxV1eX",
        "outputId": "9ed16c12-2925-4311-f2f3-69c34a0987ef"
      },
      "source": [
        "last_h = h_n.flatten(0).unsqueeze(0)\n",
        "print(last_h.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 500])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOby2F0M29_B"
      },
      "source": [
        "import torch\n",
        "import numbers\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import LayerNorm\n",
        "from torch import Tensor, Size\n",
        "from typing import Union, List, Tuple\n",
        "from torch.nn import  init\n",
        "\n",
        "class CLN (torch.nn.LayerNorm):\n",
        "  __constants__ = ['normalized_shape', 'eps', 'elementwise_affine']\n",
        "  normalized_shape: Tuple[int, ...]\n",
        "  eps: float\n",
        "  elementwise_affine: bool\n",
        "  _shape_t = Union[int, List[int], Size]\n",
        "\n",
        "  def __init__(self, normalized_shape: _shape_t, eps: float = 1e-5, elementwise_affine: bool = True,\n",
        "                 device=None, dtype=None) -> None:\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        super(LayerNorm, self).__init__()\n",
        "        if isinstance(normalized_shape, numbers.Integral):\n",
        "            # mypy error: incompatible types in assignment\n",
        "            normalized_shape = (normalized_shape,)  # type: ignore[assignment]\n",
        "        self.normalized_shape = tuple(normalized_shape)  # type: ignore[arg-type]\n",
        "        self.eps = eps\n",
        "        self.elementwise_affine = elementwise_affine\n",
        "        if self.elementwise_affine:\n",
        "            self.weight1 = Parameter(torch.empty(self.normalized_shape, **factory_kwargs))\n",
        "            self.bias1 = Parameter(torch.empty(self.normalized_shape, **factory_kwargs))\n",
        "            self.weight2 = Parameter(torch.empty(self.normalized_shape, **factory_kwargs))\n",
        "            self.bias2 = Parameter(torch.empty(self.normalized_shape, **factory_kwargs))\n",
        "        else:\n",
        "            self.register_parameter('weight', None)\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self) -> None:\n",
        "        if self.elementwise_affine:\n",
        "            init.ones_(self.weight1)\n",
        "            init.zeros_(self.bias1)\n",
        "            init.ones_(self.weight2)\n",
        "            init.zeros_(self.bias2)\n",
        "\n",
        "  def forward(self, input: Tensor) -> Tensor:\n",
        "        #batch sent of  only one style at a time\n",
        "        for input_i in input:\n",
        "            if input_i[1] == 0:\n",
        "              outputs.append(F.layer_norm(\n",
        "                input_i[0], self.normalized_shape, self.weight1, self.bias1, self.eps))\n",
        "            else:\n",
        "              outputs.append(F.layer_norm(\n",
        "                input_i[0], self.normalized_shape, self.weight2, self.bias2, self.eps))\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_layer = torch.nn.Linear(500,200)\n",
        "last_h_squeezed = linear_layer(last_h)"
      ],
      "metadata": {
        "id": "5vEyF9aaoDVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_h_squeezed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zun30bKwo3U1",
        "outputId": "63f85597-6cb1-43f0-adee-4de203665e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying Layernorm**"
      ],
      "metadata": {
        "id": "8u5d8ApLfGPN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3xK2RjbVSAg"
      },
      "source": [
        "from torch.nn import LayerNorm\n",
        "\n",
        "ln_neutral = LayerNorm(normalized_shape=[1, 200]) #TODO check normalized shape\n",
        "ln_right = LayerNorm(normalized_shape=[2, 1, 500])\n",
        "\n",
        "#check class: TODO decide how to store which data the batch belongs to \n",
        "x_cln = ln_neutral(last_h_squeezed)\n",
        "# if X[0] ==0:\n",
        "#     X = ln_neutral(X[1:])\n",
        "# else:\n",
        "#     X = ln_right(X[1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_cln.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDXcMdBJpSYV",
        "outputId": "3968c57d-3924-4002-e522-762cdc89c9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_h.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdrW-AcBpeUZ",
        "outputId": "23701f2c-7632-4c2a-bb62-b84779c3f4b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 500])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intial_hidden_state = torch.cat((last_h,x_cln), dim=-1)\n",
        "intial_hidden_state = intial_hidden_state.unsqueeze(0)\n",
        "intial_hidden_state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF8F3LjirMxW",
        "outputId": "e27557b4-0f33-4ca6-d6fd-5b4847e4abe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 700])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFQ7hZjwmpUN"
      },
      "source": [
        "gru = torch.nn.GRU(input_size=768,hidden_size = 700,num_layers= 1,batch_first = True, bidirectional = False, dropout = 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding the decoder GRU layer**"
      ],
      "metadata": {
        "id": "PHy_nMqUfKVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru_output_decoder, h_n_decoder = gru(input_gru,intial_hidden_state)"
      ],
      "metadata": {
        "id": "kuDSveXUtFae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_n_decoder.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvoIbrXnvByf",
        "outputId": "aed30a26-1334-4c14-f988-d59d9496afa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 700])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_output_decoder.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1lmZgnnuAfh",
        "outputId": "9f40a98d-924c-45c9-d274-0b732a073c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 14, 700])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_layer_2 = torch.nn.Linear(700,768)\n",
        "output_to_vocab = linear_layer_2(gru_output_decoder)"
      ],
      "metadata": {
        "id": "qBnp68Aip-aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3ZKnqnIafJtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru_output_softmax = torch.nn.functional.softmax(output_to_vocab,dim=2)\n",
        "gru_output_softmax.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEkFXJUAWETA",
        "outputId": "863e4935-6872-4ea4-d636-09a88e99a94f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 14, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    }
  ]
}